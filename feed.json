{
    "version": "https://jsonfeed.org/version/1",
    "title": "It's better to burn out than to fade away.",
    "subtitle": null,
    "icon": "https://daisiesloves.github.io/images/favicon.ico",
    "description": null,
    "home_page_url": "https://daisiesloves.github.io",
    "items": [
        {
            "id": "https://daisiesloves.github.io/2022/10/08/hdfs%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/HDFS%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/HDFS%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/",
            "url": "https://daisiesloves.github.io/2022/10/08/hdfs%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/HDFS%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/HDFS%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/",
            "title": "HDFS目录配额空间不够导致Spark任务异常",
            "date_published": "2022-10-08T07:30:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h2><span id=\"hdfs-目录配额空间不够导致-spark-任务异常\"> HDFS 目录配额空间不够导致 Spark 任务异常</span></h2>\n<h3><span id=\"错误日志如下\"> 错误日志如下：</span></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">22/10/07 03:45:18 INFO Client: Preparing resources for our AM container</span><br><span class=\"line\">22/10/07 03:45:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.</span><br><span class=\"line\">22/10/07 03:45:21 INFO Client: Uploading resource file:/tmp/spark-a23912f6-850d-45a5-88d2-a2a4376c03d9/__spark_libs__5308838579049091591.zip -&gt; hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787/__spark_libs__5308838579049091591.zip</span><br><span class=\"line\">22/10/07 03:45:22 INFO Client: Uploading resource file:/app01/upays/data-center/pay/combine/data_combine.jar -&gt; hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787/data_combine.jar</span><br><span class=\"line\">22/10/07 03:45:22 INFO Client: Deleted staging directory hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787</span><br><span class=\"line\">Exception in thread &quot;main&quot; org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /user/jyupay is exceeded: quota = 27487790694400 B = 25 TB but diskspace consumed = 27488154349032 B = 25.00 TB</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1159)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:991)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:950)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:505)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:777)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2728)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:894)</span><br><span class=\"line\">        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:581)</span><br><span class=\"line\">        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:529)</span><br><span class=\"line\">        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1036)</span><br><span class=\"line\">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:917)</span><br><span class=\"line\">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:854)</span><br><span class=\"line\">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class=\"line\">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1699)</span><br><span class=\"line\">        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2779)</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "spark",
                "hdfs"
            ]
        },
        {
            "id": "https://daisiesloves.github.io/2022/09/23/test/Test/Test/",
            "url": "https://daisiesloves.github.io/2022/09/23/test/Test/Test/",
            "title": "Test",
            "date_published": "2022-09-23T04:03:51.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p>Test post.</p>\n",
            "tags": [
                "Test"
            ]
        },
        {
            "id": "https://daisiesloves.github.io/2022/09/16/spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/Spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97Kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/Spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97Kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/",
            "url": "https://daisiesloves.github.io/2022/09/16/spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/Spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97Kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/Spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97Kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/",
            "title": "Spark启动时日志Kafka消费报错",
            "date_published": "2022-09-16T07:30:06.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3><span id=\"spark-启动报错日志\"> Spark 启动报错日志</span></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">22/09/16 06:00:29 INFO CachedKafkaConsumer: Initial fetch for spark-executor-own_combine2022082406 jyupay_py_1 7 28846987218</span><br><span class=\"line\">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT valid starting at: Fri Sep 16 06:00:29 CST 2022</span><br><span class=\"line\">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT expires: Sat Sep 17 06:00:29 CST 2022</span><br><span class=\"line\">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT refresh sleeping until: Sat Sep 17 02:19:28 CST 2022</span><br><span class=\"line\">22/09/16 06:00:29 INFO AppInfoParser: Kafka version : 2.0.0</span><br><span class=\"line\">22/09/16 06:00:29 INFO AppInfoParser: Kafka commitId : 3402a8361b734732</span><br><span class=\"line\">22/09/16 06:00:29 INFO CachedKafkaConsumer: Initial fetch for spark-executor-own_combine2022082406 jyupay_py_1 0 29119882113</span><br><span class=\"line\">22/09/16 06:00:29 INFO Metadata: Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br><span class=\"line\">22/09/16 06:00:29 INFO Metadata: Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br><span class=\"line\">22/09/16 06:00:29 ERROR Executor: Exception in task 4.1 in stage 0.0 (TID 14)</span><br><span class=\"line\">org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Offsets out of range with no configured reset policy for partitions: &#123;jyupay_py_1-7=28846987218&#125;</span><br><span class=\"line\">        at org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:970)</span><br><span class=\"line\">        at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:490)</span><br><span class=\"line\">        at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1259)</span><br><span class=\"line\">        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1187)</span><br><span class=\"line\">        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1115)</span><br><span class=\"line\">        at org.apache.spark.streaming.kafka010.CachedKafkaConsumer.poll(CachedKafkaConsumer.scala:99)</span><br><span class=\"line\">        at org.apache.spark.streaming.kafka010.CachedKafkaConsumer.get(CachedKafkaConsumer.scala:70)</span><br><span class=\"line\">        at org.apache.spark.streaming.kafka010.KafkaRDD$KafkaRDDIterator.next(KafkaRDD.scala:223)</span><br><span class=\"line\">        at org.apache.spark.streaming.kafka010.KafkaRDD$KafkaRDDIterator.next(KafkaRDD.scala:189)</span><br><span class=\"line\">        at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)</span><br><span class=\"line\">        at com.cmsz.join.PayChargeMain$.formatMessageCharge(PayChargeMain.scala:126)</span><br><span class=\"line\">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class=\"line\">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class=\"line\">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class=\"line\">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class=\"line\">        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)</span><br><span class=\"line\">        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)</span><br><span class=\"line\">        at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)</span><br><span class=\"line\">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)</span><br><span class=\"line\">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)</span><br><span class=\"line\">        at org.apache.spark.scheduler.Task.run(Task.scala:121)</span><br><span class=\"line\">        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)</span><br><span class=\"line\">        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1367)</span><br><span class=\"line\">        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)</span><br><span class=\"line\">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class=\"line\">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class=\"line\">        at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure>",
            "tags": [
                "kafka"
            ]
        },
        {
            "id": "https://daisiesloves.github.io/2022/08/26/flume-1-10%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8/Flume-1.10%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/Flume-1.10%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/",
            "url": "https://daisiesloves.github.io/2022/08/26/flume-1-10%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8/Flume-1.10%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/Flume-1.10%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/",
            "title": "Flume-1.10启动异常",
            "date_published": "2022-08-26T01:30:32.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h3><span id=\"flume-110unsupported-majorminor-version-520-启动异常\"> Flume-1.10,Unsupported major.minor version 52.0 启动异常</span></h3>\n<pre><code>执行报错：Exception in thread &quot;main&quot; java.lang.UnsupportedClassVersionError: com/heima/socket/Demo2_Receive : Unsupported major.minor version 52.0\n\n]$ java -version\njava version &quot;1.7.0_91&quot;\nOpenJDK Runtime Environment (rhel-2.6.2.3.el7-x86_64 u91-b00)\nOpenJDK 64-Bit Server VM (build 24.91-b01, mixed mode)\n\n经分排查，是生产环境jdk版本过低导致，将jdk版本升级到1.8，即可解决此报错问题。使用jd-gui工具，查看META-INF\\MANIFEST.MF中的内容，Build-Jdk属性就是jar包，JDK的版本。\n\n在flume-env.sh配置文件，指定jdk路径\nexport JAVA_HOME=&quot;/home/upays/jdk1.8.0_211/</code></pre>\n",
            "tags": [
                "Flume",
                "JDK"
            ]
        },
        {
            "id": "https://daisiesloves.github.io/2018/12/23/hello-word/Hello%20Word/Hello%20Word/",
            "url": "https://daisiesloves.github.io/2018/12/23/hello-word/Hello%20Word/Hello%20Word/",
            "title": "Hello Word",
            "date_published": "2018-12-23T04:03:51.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1><span id=\"前言\"> 前言</span></h1>\n<p>微凉<br>\n高桐深密间幽篁，乳燕声希夏日长。<br>\n独坐水亭风满袖，世间清景是微凉。</p>\n",
            "tags": [
                "Test"
            ]
        }
    ]
}