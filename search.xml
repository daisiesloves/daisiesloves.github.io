<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Flume-1.10启动异常</title>
    <url>/Flume-1.10%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="flume-110unsupported-majorminor-version-520启动异常"><a class="anchor" href="#flume-110unsupported-majorminor-version-520启动异常">#</a> Flume-1.10,Unsupported major.minor version 52.0 启动异常</h1>
<pre><code>执行报错：Exception in thread &quot;main&quot; java.lang.UnsupportedClassVersionError: com/heima/socket/Demo2_Receive : Unsupported major.minor version 52.0

]$ java -version
java version &quot;1.7.0_91&quot;
OpenJDK Runtime Environment (rhel-2.6.2.3.el7-x86_64 u91-b00)
OpenJDK 64-Bit Server VM (build 24.91-b01, mixed mode)

经分排查，是生产环境jdk版本过低导致，将jdk版本升级到1.8，即可解决此报错问题。使用jd-gui工具，查看META-INF\MANIFEST.MF中的内容，Build-Jdk属性就是jar包，JDK的版本。

在flume-env.sh配置文件，指定jdk路径
export JAVA_HOME=&quot;/home/upays/jdk1.8.0_211/</code></pre>
]]></content>
      <tags>
        <tag>flume</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop fs命令</title>
    <url>/Hadoop%20fs%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="hdfs-shell命令"><a class="anchor" href="#hdfs-shell命令">#</a> HDFS SHELL 命令</h1>
<ol>
<li>
<p>Hdfs 文件相关操作</p>
<h2 id="查看目录下文件"><a class="anchor" href="#查看目录下文件">#</a> 查看目录下文件</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -ls -h /user/jyupay</span><br><span class="line">[upays@jzhjf-core-hadoop3-c-1 ~]$ hadoop fs -ls /user/jyupay/offline/diffAndsettle/docment/backup/20221006/dc_dm_charge_diff_0077_day/CHARGE20221005100001.CMCC.0077-all</span><br><span class="line">-rw-r-----   3 jyupay bdocadm  159239323 2022-10-07 01:01 /user/jyupay/offline/diffAndsettle/docment/backup/20221006/dc_dm_charge_diff_0077_day/CHARGE20221005100001.CMCC.0077-all #第二列数字3为副本数</span><br></pre></td></tr></table></figure></p>
<h2 id="查看文件占用空间大小"><a class="anchor" href="#查看文件占用空间大小">#</a> 查看文件占用空间大小</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -du -h /user/jyupay/</span><br><span class="line">或 hadoop fs -du -h /user/jyupay</span><br></pre></td></tr></table></figure></p>
<h2 id="创建-删除文件夹"><a class="anchor" href="#创建-删除文件夹">#</a> 创建、删除文件夹</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir /pathname</span><br><span class="line">hadoop fs -rm -r /pathname</span><br></pre></td></tr></table></figure></p>
<h2 id="创建-删除-移动文件"><a class="anchor" href="#创建-删除-移动文件">#</a> 创建、删除、移动文件</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -touchz /user/jyupay/file1.txt	#创建一个空文件</span><br><span class="line">hadoop fs -rm /user/jyupay/file1.txt		#删除文件</span><br><span class="line">hadoop fs -mv hdfs://ns1/user/jyupay/.Trash/file1.txt hdfs://ns1/user/jyupay/file1/file1.txt #移动文件，如从回收站恢复文件</span><br></pre></td></tr></table></figure></p>
<h2 id="永久删除文件不放入回收站"><a class="anchor" href="#永久删除文件不放入回收站">#</a> 永久删除文件，不放入回收站</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -rm -skipTrash hadoop fs -rm -r /dir_name</span><br></pre></td></tr></table></figure></p>
<h2 id="上传-下载文件"><a class="anchor" href="#上传-下载文件">#</a> 上传、下载文件</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -put file1 /user/jyupay</span><br><span class="line">hadoop fs -copyFromLocal file1.txt /user/jyupay #copyFromLocal，从本地拷贝一个文件到hdfs</span><br><span class="line">hadoop fs -get /user/jyupay/file1</span><br><span class="line">hadoop fs -copyToLocal /user/jyupay/file1 /opt/data/file1 #copyToLocal，从hdsf拷贝文件到本地</span><br><span class="line">hadoop fs -getmerge /user/jyupay/1.txt /user/jyupay/2.txt 3.txt #getmerge合并hdfs多个文件并传至本地</span><br></pre></td></tr></table></figure></p>
<h2 id="查看文件"><a class="anchor" href="#查看文件">#</a> 查看文件</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -cat /user/jyupay/file1.txt</span><br><span class="line">hadoop fs -cat /user/jyupay/file*</span><br><span class="line">hadoop fs -tail /user/jyupay/file2.txt	#tail查看文件的最后1000字节</span><br><span class="line">hadoop fs -text /user/jyupay/file3.txt	#将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream，如果是压缩文件会先解压再查看</span><br></pre></td></tr></table></figure></p>
<h2 id="hdfs清空回收站"><a class="anchor" href="#hdfs清空回收站">#</a> Hdfs 清空回收站</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -ls -r hdfs://ns1/user/jyupay/.Trash</span><br><span class="line">hadoop fs -expunge</span><br></pre></td></tr></table></figure></p>
</li>
<li>
<p>查看目录配额相关<br />
 hadoop fs -count [-q] [-h] [-v] [-t [&lt;storage type&gt;]] [-u] [-x] [-e] &lt;path&gt;<br />
 功能描述：<br />
统计 HDFS 指定路径的可容纳文件 / 文件夹配额、空间配额、目录数、文件数及占用空间<br />
选项解释：<br />
-q：输出统计列：<br />
QUOTA（指定路径可建文件 / 文件夹数量配额）<br />
REM_QUOTA（指定路径可建文件 / 文件夹数量剩余配额）<br />
SPACE_QUOTA（指定路径可建文件 / 文件夹空间配额）<br />
REM_SPACE_QUOTA（指定路径可建文件 / 文件夹空间剩余配额）<br />
DIR_COUNT（指定路径下文件夹（包括自身）统计数）<br />
FILE_COUNT（指定路径下文件统计数）<br />
CONTENT_SIZE（指定路径下文件及文件夹大小总和）<br />
PATHNAME（指定路径）<br />
-u：输出统计列：<br />
QUOTA（指定路径可建文件 / 文件夹数量配额）<br />
REM_QUOTA（指定路径可建文件 / 文件夹数量剩余配额）<br />
SPACE_QUOTA（指定路径可建文件 / 文件夹空间配额）<br />
REM_SPACE_QUOTA（指定路径可建文件 / 文件夹空间剩余配额）<br />
PATHNAME（指定路径）<br />
-h：把数据单位显示为容易理解的单位，比如空间原单位为 byte，加入该参数后显示 k，m，g 等单位<br />
 - v：显示标题行<br />
 - t：显示每种存储类型的空间配额和使用情况。如果未给出 - u 或 - q 选项，则 - t 选项将被忽略。可选参数 storage type 支持的输入类型有：&quot;all&quot;，&quot;ram_disk&quot;，&quot;ssd&quot;，&quot;disk&quot; 或 &quot;archive&quot;。<br />
-x：统计结果排除快照。如果指定了 - u 或 - q 选项，则 - x 选项将被忽略<br />
 - e：显示指定路径的 EC 编码模式，通过列 ERASURECODING_POLICY 显示</p>
<h2 id="查看hdfs空间配额信息"><a class="anchor" href="#查看hdfs空间配额信息">#</a> 查看 hdfs 空间配额信息</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -count -q -v /user/bdoc/35/hive/jyupay</span><br><span class="line">或 hdfs dfs -count -q -v /user/jyupay/</span><br></pre></td></tr></table></figure></p>
</li>
</ol>
]]></content>
      <tags>
        <tag>hadoop</tag>
        <tag>hdfs</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS目录配额空间不够导致Spark任务异常</title>
    <url>/Hdfs%E7%9B%AE%E5%BD%95%E9%85%8D%E9%A2%9D%E7%A9%BA%E9%97%B4%E4%B8%8D%E5%A4%9F%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="hdfs目录配额空间不够导致spark任务异常"><a class="anchor" href="#hdfs目录配额空间不够导致spark任务异常">#</a> HDFS 目录配额空间不够导致 Spark 任务异常</h2>
<h3 id="错误日志如下"><a class="anchor" href="#错误日志如下">#</a> 错误日志如下：</h3>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/10/07 03:45:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.</span><br><span class="line">22/10/07 03:45:21 INFO Client: Uploading resource file:/tmp/spark-a23912f6-850d-45a5-88d2-a2a4376c03d9/__spark_libs__5308838579049091591.zip -&gt; hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787/__spark_libs__5308838579049091591.zip</span><br><span class="line">22/10/07 03:45:22 INFO Client: Uploading resource file:/app01/upays/data-center/pay/combine/data_combine.jar -&gt; hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787/data_combine.jar</span><br><span class="line">22/10/07 03:45:22 INFO Client: Deleted staging directory hdfs://router-fed/user/jyupay/.sparkStaging/application_1663262516437_821787</span><br><span class="line">Exception in thread &quot;main&quot; org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /user/jyupay is exceeded: quota = 27487790694400 B = 25 TB but diskspace consumed = 27488154349032 B = 25.00 TB</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyStoragespaceQuota(DirectoryWithQuotaFeature.java:195)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:222)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:1159)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:991)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:950)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:505)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:777)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:260)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2728)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:894)</span><br><span class="line">        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:581)</span><br><span class="line">        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:529)</span><br><span class="line">        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1036)</span><br><span class="line">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:917)</span><br><span class="line">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:854)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1699)</span><br><span class="line">        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2779)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>hdfs</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark启动时日志Kafka消费报错</title>
    <url>/Spark%E5%90%AF%E5%8A%A8%E6%97%B6%E6%97%A5%E5%BF%97Kafka%E6%B6%88%E8%B4%B9%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="spark启动报错日志"><a class="anchor" href="#spark启动报错日志">#</a> Spark 启动报错日志</h1>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/09/16 06:00:29 INFO CachedKafkaConsumer: Initial fetch for spark-executor-own_combine2022082406 jyupay_py_1 7 28846987218</span><br><span class="line">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT valid starting at: Fri Sep 16 06:00:29 CST 2022</span><br><span class="line">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT expires: Sat Sep 17 06:00:29 CST 2022</span><br><span class="line">22/09/16 06:00:29 INFO KerberosLogin: [Principal=jyupay@ZHKDC]: TGT refresh sleeping until: Sat Sep 17 02:19:28 CST 2022</span><br><span class="line">22/09/16 06:00:29 INFO AppInfoParser: Kafka version : 2.0.0</span><br><span class="line">22/09/16 06:00:29 INFO AppInfoParser: Kafka commitId : 3402a8361b734732</span><br><span class="line">22/09/16 06:00:29 INFO CachedKafkaConsumer: Initial fetch for spark-executor-own_combine2022082406 jyupay_py_1 0 29119882113</span><br><span class="line">22/09/16 06:00:29 INFO Metadata: Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br><span class="line">22/09/16 06:00:29 INFO Metadata: Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br><span class="line">22/09/16 06:00:29 ERROR Executor: Exception in task 4.1 in stage 0.0 (TID 14)</span><br><span class="line">org.apache.kafka.clients.consumer.OffsetOutOfRangeException: Offsets out of range with no configured reset policy for partitions: &#123;jyupay_py_1-7=28846987218&#125;</span><br><span class="line">        at org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch(Fetcher.java:970)</span><br><span class="line">        at org.apache.kafka.clients.consumer.internals.Fetcher.fetchedRecords(Fetcher.java:490)</span><br><span class="line">        at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1259)</span><br><span class="line">        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1187)</span><br><span class="line">        at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1115)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.CachedKafkaConsumer.poll(CachedKafkaConsumer.scala:99)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.CachedKafkaConsumer.get(CachedKafkaConsumer.scala:70)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.KafkaRDD$KafkaRDDIterator.next(KafkaRDD.scala:223)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.KafkaRDD$KafkaRDDIterator.next(KafkaRDD.scala:189)</span><br><span class="line">        at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$.formatMessageCharge(PayChargeMain.scala:126)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class="line">        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)</span><br><span class="line">        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)</span><br><span class="line">        at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)</span><br><span class="line">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)</span><br><span class="line">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)</span><br><span class="line">        at org.apache.spark.scheduler.Task.run(Task.scala:121)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)</span><br><span class="line">        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1367)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka topic配置错误报错信息</title>
    <url>/Kafka-topic%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AF%E6%8A%A5%E9%94%99%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="kafka错误日志如下原因是kafka-topic信息配置错误"><a class="anchor" href="#kafka错误日志如下原因是kafka-topic信息配置错误">#</a> Kafka 错误日志如下，原因是 kafka topic 信息配置错误</h1>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">16 Jun 2022 14:32:12,697 INFO  [New I/O server boss #11] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0x8a66e568, /10.209.9.3:49176 =&gt; /10.209.36.55:6572] OPEN</span><br><span class="line">16 Jun 2022 14:32:12,698 INFO  [New I/O worker #1] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0x8a66e568, /10.209.9.3:49176 =&gt; /10.209.36.55:6572] BOUND: /10.209.36.55:6572</span><br><span class="line">16 Jun 2022 14:32:12,698 INFO  [New I/O worker #1] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0x8a66e568, /10.209.9.3:49176 =&gt; /10.209.36.55:6572] CONNECTED: /10.209.9.3:49176</span><br><span class="line">16 Jun 2022 14:33:14,494 WARN  [kafka-producer-network-thread | producer-1] (org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse:968)  - [Producer clientId=producer-1] Error while fetching metadata with correlation id 9 : &#123;jyucmall_info_sc_3=UNKNOWN_TOPIC_OR_PARTITION&#125;</span><br><span class="line">16 Jun 2022 14:33:14,494 INFO  [kafka-producer-network-thread | producer-1] (org.apache.kafka.clients.Metadata.update:285)  - Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br><span class="line">16 Jun 2022 14:33:15,115 WARN  [kafka-producer-network-thread | producer-1] (org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse:968)  - [Producer clientId=producer-1] Error while fetching metadata with correlation id 15 : &#123;jyucmall_info_sc_3=UNKNOWN_TOPIC_OR_PARTITION&#125;</span><br><span class="line">16 Jun 2022 14:33:15,905 WARN  [kafka-producer-network-thread | producer-1] (org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleCompletedMetadataResponse:968)  - [Producer clientId=producer-1] Error while fetching metadata with correlation id 23 : &#123;jyucmall_info_sc_3=UNKNOWN_TOPIC_OR_PARTITION&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Clickhouse时间日期统计数据</title>
    <url>/Clickhouse%E6%97%B6%E9%97%B4%E6%97%A5%E6%9C%9F%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="clickhouse按照时间日期统计数据"><a class="anchor" href="#clickhouse按照时间日期统计数据">#</a> Clickhouse 按照时间日期统计数据</h1>
<h2 id="按分钟统计数据"><a class="anchor" href="#按分钟统计数据">#</a> 按分钟统计数据</h2>
<pre><code>toStartOfInterval函数，按分钟统计数据
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select toStartOfInterval(reqDateTime1, INTERVAL 60  minute ) as minute, count() as volume from dwd_cz_hebao_message_detail_cz where settleDate=&#x27;2022-10-24&#x27; and reqDateTime1 &gt;= &#x27;2022-10-24 08:00:00&#x27; and reqDateTime1 &lt;= &#x27;2022-10-24 18:59:59&#x27; and rspCode5=&#x27;010A00&#x27; group by minute order by minute;</span><br></pre></td></tr></table></figure></p>
<h2 id="按天统计数据"><a class="anchor" href="#按天统计数据">#</a> 按天统计数据</h2>
<pre><code>toStartOfDay函数，按天统计数据
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select toStartOfDay(reqDateTime1) as time_interval, count(*) from dwd_cz_hebao_message_detail_cz where  reqDateTime1 &gt;= &#x27;2022-10-16 00:00:00&#x27; and reqDateTime1 &lt;&#x27;2022-10-25 00:00:00&#x27; group by time_interval order by time_interval;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>clickhouse</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink任务提交失败报错记录</title>
    <url>/Flink%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%A4%B1%E8%B4%A5%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="flink任务提交失败报错记录"><a class="anchor" href="#flink任务提交失败报错记录">#</a> Flink 任务提交失败报错记录</h1>
<h2 id="错误日志信息如下"><a class="anchor" href="#错误日志信息如下">#</a> 错误日志信息如下</h2>
<pre><code>数据量级过大，程序处理不过来，导到数据库锁表只读。
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Caused by: java.io.IOException: ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 242, host: 10.253.50.56, port: 8123; Code: 242, e.displayText() = DB::Exception: Table is in readonly mode (zookeeper path: /clickhouse/tables/01-08/dwd_cz_monitor_message_detail_cz_local) (version 20.8.3.18)</span><br><span class="line"></span><br><span class="line">        at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.flush(JdbcBatchingOutputFormat.java:179)</span><br><span class="line">        at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.writeRecord(JdbcBatchingOutputFormat.java:156)</span><br><span class="line">        ... 22 more</span><br><span class="line">Caused by: ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 242, host: 10.253.50.56, port: 8123; Code: 242, e.displayText() = DB::Exception: Table is in readonly mode (zookeeper path: /clickhouse/tables/01-08/dwd_cz_monitor_message_detail_cz_local) (version 20.8.3.18)</span><br><span class="line"></span><br><span class="line">        at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:58)</span><br><span class="line">        at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:28)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHouseStatementImpl.checkForErrorAndThrow(ClickHouseStatementImpl.java:875)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:851)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:824)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:817)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHousePreparedStatementImpl.executeBatch(ClickHousePreparedStatementImpl.java:335)</span><br><span class="line">        at ru.yandex.clickhouse.ClickHousePreparedStatementImpl.executeBatch(ClickHousePreparedStatementImpl.java:320)</span><br><span class="line">        at org.apache.flink.connector.jdbc.internal.executor.SimpleBatchStatementExecutor.executeBatch(SimpleBatchStatementExecutor.java:71)</span><br><span class="line">        at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.attemptFlush(JdbcBatchingOutputFormat.java:202)</span><br><span class="line">        at org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat.flush(JdbcBatchingOutputFormat.java:173)</span><br><span class="line">        ... 23 more</span><br><span class="line">Caused by: java.lang.Throwable: Code: 242, e.displayText() = DB::Exception: Table is in readonly mode (zookeeper path: /clickhouse/tables/01-08/dwd_cz_monitor_message_detail_cz_local) (version 20.8.3.18)</span><br><span class="line"></span><br><span class="line">        at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:53)</span><br><span class="line">        ... 33 more</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>clickhouse</tag>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Java程序报错NoClassDefFoundError</title>
    <url>/Java%E7%A8%8B%E5%BA%8F%E6%8A%A5%E9%94%99NoClassDefFoundError/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="javalangnoclassdeffounderror-comalibabafastjson2jsonexception"><a class="anchor" href="#javalangnoclassdeffounderror-comalibabafastjson2jsonexception">#</a> java.lang.NoClassDefFoundError: com/alibaba/fastjson2/JSONException</h1>
<pre><code>程序没有找到类，检查项目依赖的jar包
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/11/15 15:30:16 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 2)</span><br><span class="line">java.lang.NoClassDefFoundError: com/alibaba/fastjson2/JSONException</span><br><span class="line">        at com.cmsz.join.PayChargeMain$$anonfun$formatMessageCharge$1.apply$mcV$sp(PayChargeMain.scala:136)</span><br><span class="line">        at scala.util.control.Breaks.breakable(Breaks.scala:38)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$.formatMessageCharge(PayChargeMain.scala:131)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class="line">        at com.cmsz.join.PayChargeMain$$anonfun$3.apply(PayChargeMain.scala:66)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)</span><br><span class="line">        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)</span><br><span class="line">        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)</span><br><span class="line">        at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)</span><br><span class="line">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)</span><br><span class="line">        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)</span><br><span class="line">        at org.apache.spark.scheduler.Task.run(Task.scala:121)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)</span><br><span class="line">        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1367)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: com.alibaba.fastjson2.JSONException</span><br><span class="line">        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span><br><span class="line">        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">        ... 19 more</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java应用连接数据库查询时java.net.SocketTimeoutException</title>
    <url>/Java%E7%A8%8B%E5%BA%8F%E6%8A%A5%E9%94%99SocketTimeoutException/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="java应用连接数据库查询时javanetsockettimeoutexception报错"><a class="anchor" href="#java应用连接数据库查询时javanetsockettimeoutexception报错">#</a> Java 应用连接数据库查询时 java.net.SocketTimeoutException 报错</h1>
<pre><code>应用程序连接数据库时，连接超时查询数据失败。出现这个问题的原因是OKhttp没有留足够的时间连接和处理数据，造成了超时的情况。
</code></pre>
<h2 id="解决方案"><a class="anchor" href="#解决方案">#</a> 解决方案：</h2>
<pre><code>1. 将超时时间延长即可
2. 连接数据库配置多个节点
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#clickhouse连接配置</span><br><span class="line">clickhouse.source.url=jdbc:clickhouse://172.20.30.20:8123,172.20.30.20:8124/cmsz</span><br><span class="line">clickhouse.source.database=cmsz</span><br><span class="line">clickhouse.source.user=root</span><br><span class="line">clickhouse.source.password=ENC(PUl8y0UzFgOTUUMJOykhKxBwJ5pv0lO2)</span><br><span class="line">clickhouse.source.setSocketTimeout=300000</span><br><span class="line">clickhouse.source.maxRetryTimes=3</span><br></pre></td></tr></table></figure></p>
<h2 id="日志报错信息"><a class="anchor" href="#日志报错信息">#</a> 日志报错信息：</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2023-01-29 22:21:15.007 [pool-3-thread-6] [ERROR] -统计预下单金科数据失败，sql=select </span><br><span class="line"> &#x27;01&#x27; as BUSI_CODE,</span><br><span class="line"> &#x27;05&#x27; as INTERFACE_CODE,</span><br><span class="line"> &#x27;202301292219&#x27; as DATA_TIME,</span><br><span class="line"> FINISH_COUNT,</span><br><span class="line"> YW_SUCC_COUNT,</span><br><span class="line"> FINISH_COUNT-FAIL as JK_SUCC_COUNT,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(YW_SUCC_COUNT/FINISH_COUNT,5),0) as YW_SUCC_RATE,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(JK_SUCC_COUNT/FINISH_COUNT,5),0) as JK_SUCC_RATE,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(timeTotal/FINISH_COUNT,0),0) as AVG_TIME,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time1/FINISH_COUNT,5),0) as PER_1,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time2/FINISH_COUNT,5),0) as PER_2,</span><br><span class="line">...skipping...</span><br><span class="line">java.net.SocketTimeoutException: timeout</span><br><span class="line">        at okio.SocketAsyncTimeout.newTimeoutException(JvmOkio.kt:143)</span><br><span class="line">        at okio.AsyncTimeout.access$newTimeoutException(AsyncTimeout.kt:162)</span><br><span class="line">        at okio.AsyncTimeout$source$1.read(AsyncTimeout.kt:335)</span><br><span class="line">        at okio.RealBufferedSource.indexOf(RealBufferedSource.kt:427)</span><br><span class="line">        at okio.RealBufferedSource.readUtf8LineStrict(RealBufferedSource.kt:320)</span><br><span class="line">        at okhttp3.internal.http1.HeadersReader.readLine(HeadersReader.kt:29)</span><br><span class="line">        at okhttp3.internal.http1.Http1ExchangeCodec.readResponseHeaders(Http1ExchangeCodec.kt:178)</span><br><span class="line">        at okhttp3.internal.connection.Exchange.readResponseHeaders(Exchange.kt:106)</span><br><span class="line">        at okhttp3.internal.http.CallServerInterceptor.intercept(CallServerInterceptor.kt:79)</span><br><span class="line">        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)</span><br><span class="line">        at okhttp3.internal.connection.ConnectInterceptor.intercept(ConnectInterceptor.kt:34)</span><br><span class="line">        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)</span><br><span class="line">        at okhttp3.internal.cache.CacheInterceptor.intercept(CacheInterceptor.kt:95)</span><br><span class="line">        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)</span><br><span class="line">        at okhttp3.internal.http.BridgeInterceptor.intercept(BridgeInterceptor.kt:83)</span><br><span class="line">        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)</span><br><span class="line">        at okhttp3.internal.http.RetryAndFollowUpInterceptor.intercept(RetryAndFollowUpInterceptor.kt:76)</span><br><span class="line">        at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)</span><br><span class="line">        at okhttp3.internal.connection.RealCall.getResponseWithInterceptorChain$okhttp(RealCall.kt:201)</span><br><span class="line">        at okhttp3.internal.connection.RealCall.execute(RealCall.kt:154)</span><br><span class="line">        at com.cmsz.util.CkClient.getResultString(CkClient.java:108)</span><br><span class="line">        at com.cmsz.util.CkClient.getCKData(CkClient.java:75)</span><br><span class="line">        at com.cmsz.service.HandleDataServiceImpl.getJkNotifyPushData(HandleDataServiceImpl.java:1362)</span><br><span class="line">        at com.cmsz.task.PushDataTask.pushJinKeNotifyRateData(PushDataTask.java:734)</span><br><span class="line">        at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)</span><br><span class="line">        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)</span><br><span class="line">        at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)</span><br><span class="line">        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: java.net.SocketException: Socket closed</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:204)</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:141)</span><br><span class="line">        at okio.InputStreamSource.read(JvmOkio.kt:90)</span><br><span class="line">        at okio.AsyncTimeout$source$1.read(AsyncTimeout.kt:129)</span><br><span class="line">        ... 34 common frames omitted</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java空指针异常报错java.lang.NullPointerException</title>
    <url>/Java%E7%A9%BA%E6%8C%87%E9%92%88%E5%BC%82%E5%B8%B8%E6%8A%A5%E9%94%99java-lang-NullPointerException/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="java程序空指针异常报错javalangnullpointerexception-null"><a class="anchor" href="#java程序空指针异常报错javalangnullpointerexception-null">#</a> Java 程序空指针异常报错 java.lang.NullPointerException: null</h1>
<pre><code>错误日志如下：
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2022-10-25 13:40:15.152 [pool-3-thread-3] [INFO] -聚合支付分中心数据[&#123;&quot;BUSI_CODE&quot;:&quot;01&quot;,&quot;DATA_TIME&quot;:&quot;202210251339&quot;,&quot;CENTER_CODE&quot;:&quot;01&quot;,&quot;INTERFACE_CODE&quot;:&quot;07&quot;,&quot;FINISH_COUNT&quot;:&quot;1818&quot;,&quot;YW_SUCC_COUNT&quot;:&quot;1811&quot;,&quot;YW_SUCC_RATE&quot;:&quot;0.99614&quot;,&quot;JK_SUCC_COUNT&quot;:&quot;1818&quot;,&quot;JK_SUCC_RATE&quot;:&quot;1&quot;,&quot;INNER_AVG_TIME&quot;:&quot;25&quot;,&quot;INNER_PER_1&quot;:&quot;1&quot;,&quot;INNER_PER_2&quot;:&quot;0&quot;,&quot;INNER_PER_3&quot;:&quot;0&quot;,&quot;INNER_PER_4&quot;:&quot;0&quot;&#125;, &#123;&quot;BUSI_CODE&quot;:&quot;01&quot;,&quot;DATA_TIME&quot;:&quot;202210251339&quot;,&quot;CENTER_CODE&quot;:&quot;02&quot;,&quot;INTERFACE_CODE&quot;:&quot;07&quot;,&quot;FINISH_COUNT&quot;:&quot;188&quot;,&quot;YW_SUCC_COUNT&quot;:&quot;168&quot;,&quot;YW_SUCC_RATE&quot;:&quot;0.89361&quot;,&quot;JK_SUCC_COUNT&quot;:&quot;188&quot;,&quot;JK_SUCC_RATE&quot;:&quot;1&quot;,&quot;INNER_AVG_TIME&quot;:&quot;17&quot;,&quot;INNER_PER_1&quot;:&quot;1&quot;,&quot;INNER_PER_2&quot;:&quot;0&quot;,&quot;INNER_PER_3&quot;:&quot;0&quot;,&quot;INNER_PER_4&quot;:&quot;0&quot;&#125;, &#123;&quot;BUSI_CODE&quot;:&quot;01&quot;,&quot;DATA_TIME&quot;:&quot;202210251339&quot;,&quot;CENTER_CODE&quot;:&quot;02&quot;,&quot;INTERFACE_CODE&quot;:&quot;02&quot;,&quot;FINISH_COUNT&quot;:&quot;81&quot;,&quot;YW_SUCC_COUNT&quot;:&quot;53&quot;,&quot;YW_SUCC_RATE&quot;:&quot;0.65432&quot;,&quot;JK_SUCC_COUNT&quot;:&quot;81&quot;,&quot;JK_SUCC_RATE&quot;:&quot;1&quot;,&quot;INNER_AVG_TIME&quot;:&quot;40&quot;,&quot;INNER_PER_1&quot;:&quot;1&quot;,&quot;INNER_PER_2&quot;:&quot;0&quot;,&quot;INNER_PER_3&quot;:&quot;0&quot;,&quot;INNER_PER_4&quot;:&quot;0&quot;&#125;]</span><br><span class="line">2022-10-25 13:40:15.170 [pool-3-thread-6] [INFO] -分商户结果通知耗时指标推送rabbitmq成功</span><br><span class="line">2022-10-25 13:40:15.170 [pool-3-thread-6] [INFO] -推送分商户结果通知耗时指标定时任务结束</span><br><span class="line">2022-10-25 13:40:15.174 [pool-3-thread-3] [INFO] -推送聚合支付统一支付分中心指标定时任务结束</span><br><span class="line">2022-10-25 13:40:15.182 [pool-3-thread-8] [WARN] -充值统一支付分中心sql=select </span><br><span class="line"> &#x27;02&#x27; as BUSI_CODE,</span><br><span class="line"> &#x27;03&#x27; as INTERFACE_CODE,</span><br><span class="line"> &#x27;202210251339&#x27; as DATA_TIME,</span><br><span class="line"> CENTER_CODE,</span><br><span class="line"> FINISH_COUNT,</span><br><span class="line"> YW_SUCC_COUNT,</span><br><span class="line"> FINISH_COUNT-FAIL as JK_SUCC_COUNT,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(YW_SUCC_COUNT/FINISH_COUNT,5),0) as YW_SUCC_RATE,</span><br><span class="line"> if(FINISH_COUNT&gt;0,1-floor(FAIL/FINISH_COUNT,5),0) as JK_SUCC_RATE,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(utimeTotal/FINISH_COUNT,0),0) as SYNC_AVG_TIME,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(utime1/FINISH_COUNT,5),0) as SYNC_PER_1,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(utime2/FINISH_COUNT,5),0) as SYNC_PER_2,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(utime3/FINISH_COUNT,5),0) as SYNC_PER_3,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(utime4/FINISH_COUNT,5),0) as SYNC_PER_4,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(timeTotal/FINISH_COUNT,0),0) as INNER_AVG_TIME,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time1/FINISH_COUNT,5),0) as INNER_PER_1,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time2/FINISH_COUNT,5),0) as INNER_PER_2,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time3/FINISH_COUNT,5),0) as INNER_PER_3,</span><br><span class="line"> if(FINISH_COUNT&gt;0,floor(time4/FINISH_COUNT,5),0) as INNER_PER_4</span><br><span class="line">from (</span><br><span class="line">select</span><br><span class="line">  CENTER_CODE, </span><br><span class="line">  count() as FINISH_COUNT,</span><br><span class="line">  countIf(resultCode5 in (&#x27;2001&#x27;,&#x27;010A00&#x27;,&#x27;014A08&#x27;,&#x27;014A17&#x27;)) as YW_SUCC_COUNT,</span><br><span class="line">  countIf(resultCode5=&#x27;015A06&#x27;) as FAIL,</span><br><span class="line">  sum(upayTime) as utimeTotal,</span><br><span class="line">  sum(if(upayTime&lt;=1000,1,0)) as utime1,</span><br><span class="line">  sum(if(upayTime&gt;1000 and upayTime&lt;=3000,1,0)) as utime2,</span><br><span class="line">  sum(if(upayTime&gt;3000 and upayTime&lt;=10000,1,0)) as utime3,</span><br><span class="line">  sum(if(upayTime&gt;10000,1,0)) as utime4,</span><br><span class="line">  sum(handleTime) as timeTotal,</span><br><span class="line">  sum(if(handleTime&lt;=1000,1,0)) as time1,</span><br><span class="line">  sum(if(handleTime&gt;1000 and handleTime&lt;=3000,1,0)) as time2,</span><br><span class="line">  sum(if(handleTime&gt;3000 and handleTime&lt;=10000,1,0)) as time3,</span><br><span class="line">  sum(if(handleTime&gt;10000,1,0)) as time4</span><br><span class="line">from </span><br><span class="line">  (</span><br><span class="line">  select </span><br><span class="line">    serial,</span><br><span class="line">    if(reqDateTime2&gt;&#x27;1971-01-01 08:00:00&#x27;,toUnixTimestamp64Milli(reqDateTime2)-toUnixTimestamp64Milli(reqDateTime1),10) as upayTime,</span><br><span class="line">    if(reqDateTime5&gt;&#x27;1971-01-01 08:00:00&#x27;,toUnixTimestamp64Milli(reqDateTime5)-toUnixTimestamp64Milli(reqDateTime1),10000) as handleTime1, </span><br><span class="line">    if(reqDateTime4&gt;&#x27;1971-01-01 08:00:00&#x27; and reqDateTime3&gt;&#x27;1971-01-01 08:00:00&#x27;,toUnixTimestamp64Milli(reqDateTime4)-toUnixTimestamp64Milli(reqDateTime3),0) as handleTime2,</span><br><span class="line">    handleTime1-handleTime2 as handleTime,</span><br><span class="line">    resultCode5</span><br><span class="line">  from cmsz.dwd_jf_zxjf_message_detail_jf</span><br><span class="line">--</span><br><span class="line">java.lang.NullPointerException: null</span><br><span class="line">        at java.math.BigDecimal.&lt;init&gt;(BigDecimal.java:806)</span><br><span class="line">        at com.cmsz.task.PushDataTask.perMin(PushDataTask.java:879)</span><br><span class="line">        at com.cmsz.task.PushDataTask.lambda$pushCenterData$4(PushDataTask.java:474)</span><br><span class="line">        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374)</span><br><span class="line">        at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)</span><br><span class="line">        at com.cmsz.task.PushDataTask.pushCenterData(PushDataTask.java:466)</span><br><span class="line">        at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)</span><br><span class="line">        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)</span><br><span class="line">        at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)</span><br><span class="line">        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">        at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)</span><br><span class="line">        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown简单用法</title>
    <url>/Markdown%E7%AE%80%E5%8D%95%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="markdown基本语法"><a class="anchor" href="#markdown基本语法">#</a> Markdown 基本语法</h1>
<pre><code>markdown是一种纯文本格式的标记语言。通过简单的标记语法,它可以使普通文本内容具有一定的格式.
</code></pre>
<h1 id="标题"><a class="anchor" href="#标题">#</a> 标题</h1>
<pre><code># 这是一级标题
## 这是二级标题
### 这是三级标题
#### 这是四级标题
##### 这是五级标题
###### 这是六级标题
</code></pre>
<h1 id="字体"><a class="anchor" href="#字体">#</a> 字体</h1>
<pre><code>斜体 要倾斜的文字左右分别用一个*号包起来
	*这是倾斜的文字*
加粗 要加粗的文字左右分别用两个*号包起来
	**这是加粗的文字**	
斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来
	***这是斜体加粗的文字***
删除线 要加删除线的文字左右分别用两个~~号包起来
	~~这是加删除线的文字~~
</code></pre>
<h1 id="分割线"><a class="anchor" href="#分割线">#</a> 分割线</h1>
<pre><code>三个或者三个以上的 - 或者 * 都可以
	---
	----
	***
	*****
</code></pre>
<h1 id="超链接"><a class="anchor" href="#超链接">#</a> 超链接</h1>
<pre><code>[超链接名](超链接地址 &quot;超链接title&quot;) #title可以不用添加
[谷歌网址](www.google.com)
</code></pre>
<h1 id="列表"><a class="anchor" href="#列表">#</a> 列表</h1>
<pre><code>1. 无序列表
	语法:无序列表用 - + * 任何一种都可以
	- 列表内容
	+ 列表内容
	* 列表内容

	注意:- + * 跟内容之间都要有一个空格

2. 有序列表
	语法:数字加点，注意序号，跟内容之间要有空格
	1. 列表内容
	2. 列表内容
	3. 列表内容

3. 列表嵌套
	上一级和下一级之间敲三个空格即可
</code></pre>
<h1 id="代码"><a class="anchor" href="#代码">#</a> 代码</h1>
<pre><code>1. 单行代码:代码之间分别用一个反引号包起来
	`代码内容`

2. 代码块:代码之间分别用三个反引号包起来,且两边的反引号单独占一行	
	(```)
	  代码...
	  代码...
	  代码...
	(```)
</code></pre>
<p>​		<br />
​		<br />
​		<br />
​		<br />
​		<br />
​		<br />
​		<br />
​		<br />
​		<br />
​</p>
]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql数据库表没有创建分区导致Spark任务异常</title>
    <url>/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E6%B2%A1%E6%9C%89%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA%E5%AF%BC%E8%87%B4Spark%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="mysql数据库表没有创建分区导致spark任务异常"><a class="anchor" href="#mysql数据库表没有创建分区导致spark任务异常">#</a> Mysql 数据库表没有创建分区导致 Spark 任务异常</h1>
<pre><code>Spark向Mysql插入数据，因Mysql表没有创建分区，导致数据写入失败。期间通过Web页面查看spark任务，并未出现相关异常。原因是java程序中定义了try catch机制，当try catch捕获到异常时，程序不会异常退出。
</code></pre>
<h1 id="spark日志报错如下"><a class="anchor" href="#spark日志报错如下">#</a> Spark 日志报错如下：</h1>
<pre><code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/10/19 16:12:32 WARN SparkUtil$: [!] filter log:2022-10-19 16:12:13.677#nj-b04-hnpay-front02_172.16.32.80_8402#Serial:202210191612136769940760414152#charge-merchant-front|ChargeController|RCV_REQ_MER|接收到商户的充值请求报文：&lt;?xml ver</span><br><span class="line">sion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;GPay&gt;&lt;Header&gt;&lt;ActivityCode&gt;C001_001&lt;/ActivityCode&gt;&lt;ReqSys&gt;0077&lt;/ReqSys&gt;&lt;ReqChannel&gt;PORTA&lt;/ReqChannel&gt;&lt;ReqDate&gt;20221019&lt;/ReqDate&gt;&lt;ReqTransID&gt;20221019161213645000000957081775&lt;/ReqTransID&gt;&lt;ReqDateTime&gt;202210191</span><br><span class="line">61213645&lt;/ReqDateTime&gt;&lt;ActionCode&gt;0&lt;/ActionCode&gt;&lt;RcvSys&gt;0001&lt;/RcvSys&gt;&lt;/Header&gt;&lt;Body&gt;&lt;OrderID&gt;00772022101916121362457315971050&lt;/OrderID&gt;&lt;PayTransID&gt;20221019161213645000000957081775&lt;/PayTransID&gt;&lt;IDType&gt;01&lt;/IDType&gt;&lt;IDValue&gt;13962758433&lt;/IDVa</span><br><span class="line">lue&gt;&lt;HomeProv&gt;250&lt;/HomeProv&gt;&lt;Payment&gt;10000&lt;/Payment&gt;&lt;ChargeMoney&gt;10000&lt;/ChargeMoney&gt;&lt;ProdDiscount&gt;0&lt;/ProdDiscount&gt;&lt;DiscountRate&gt;1&lt;/DiscountRate&gt;&lt;PayWay&gt;CMPAY-APP&lt;/PayWay&gt;&lt;BuyerID&gt;0&lt;/BuyerID&gt;&lt;ServiceFee&gt;36&lt;/ServiceFee&gt;&lt;FeedBackURL&gt;http://</span><br><span class="line">10.254.195.104/huafei-unifiedpay-in/tmall/v1/rechargeNotify&lt;/FeedBackURL&gt;&lt;PayOrganID&gt;0077&lt;/PayOrganID&gt;&lt;BusinessChannels&gt;1000000002230300542&lt;/BusinessChannels&gt;&lt;ChannelsIP&gt;&lt;/ChannelsIP&gt;&lt;Reserve4&gt;4&lt;/Reserve4&gt;&lt;/Body&gt;&lt;Sign&gt;&lt;SignFlag&gt;1&lt;/SignFl</span><br><span class="line">ag&gt;&lt;CerID&gt;1247153&lt;/CerID&gt;&lt;SignValue&gt;Tn4Pfhu1Xr0yUDValz7gp0OjX+8NUaliJkre7l6+1TLYa0x6erMxsG8Z5VrtyzmRPt6VBEzkh78eT6GRVMl2/0Odw6Ej9n/IUuPWlO/pkPx8+hOkJ7J5PH9PmeccQyiQcsM2mg9qLtwJywzqnjM3Ge10n8iFH9DgxS+a+ZXawAGwq3SLI0Bg+5H0YArRZLE4LjoKdFcse</span><br><span class="line">U8urB9bfNQ+5LhpFXA7UPOyxi4mbw6rHiyqv2jXI62upo7vPIvocKe5oKpGzppxAGRggvnP6h6MklpvxjHrdiJmMy2GamK3A4GwNV+PLnYV1wSesvvp+nmnEQvHq8TVZvbVlWxO7PYcpw==&lt;/SignValue&gt;&lt;/Sign&gt;&lt;/GPay&gt;#####2022-10-19 16:12:13.689#nj-b04-hnpay-front02_172.16.32.80_8402#</span><br><span class="line">Serial:202210191612136769940760414152#charge-merchant-front|ChargeController|RSP_SYNC_MER|返回给商户的充值请求同步响应：&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;GPay&gt;&lt;Header&gt;&lt;ActivityCode&gt;C001_001&lt;/ActivityCode&gt;&lt;ActionCode&gt;1&lt;/ActionCode&gt;&lt;R</span><br><span class="line">eqSys&gt;0077&lt;/ReqSys&gt;&lt;ReqTransID&gt;20221019161213645000000957081775&lt;/ReqTransID&gt;&lt;ReqDate&gt;20221019&lt;/ReqDate&gt;&lt;ReqDateTime&gt;20221019161213645&lt;/ReqDateTime&gt;&lt;RcvSys&gt;0001&lt;/RcvSys&gt;&lt;ReqChannel&gt;PORTA&lt;/ReqChannel&gt;&lt;RcvDate&gt;20221019&lt;/RcvDate&gt;&lt;RcvTransID&gt;</span><br><span class="line">202210191612136769940760414152&lt;/RcvTransID&gt;&lt;RcvDateTime&gt;20221019161213677&lt;/RcvDateTime&gt;&lt;RspCode&gt;010A00&lt;/RspCode&gt;&lt;RspDesc&gt;成功&lt;/RspDesc&gt;&lt;/Header&gt;&lt;Body&gt;&lt;/Body&gt;&lt;Sign&gt;&lt;SignFlag&gt;1&lt;/SignFlag&gt;&lt;CerID&gt;11D9668&lt;/CerID&gt;&lt;SignValue&gt;fW8BCnwT9nc2UG1zT+3</span><br><span class="line">odTeAiVbgS4fzKko7B9cg7d7D0fDuGIrl2uJj9pK5q8JPgp3XKzR8G+I6yNYkVfrrL3cr6VCWoek9oLlB1xYUUM9smpfBFVz9iNbvC7GtazRfVlbIVP3CtA0faubuu1CrUW/ePZlzGJ/VsWm8ejQHNjg=&lt;/SignValue&gt;&lt;/Sign&gt;&lt;/GPay&gt;#####2022-10-19 16:12:13.695#nj-a11-hnpay-crmfront03_172.1</span><br><span class="line">6.32.47_8802#Serial:202210191612136769940760414152#charge-crm-front|CrmChargeService|REQ_CRM|发送充值请求给省Boss：&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;InterBOSS&gt;&lt;Version&gt;0100&lt;/Version&gt;&lt;TestFlag&gt;0&lt;/TestFlag&gt;&lt;BIPType&gt;&lt;BIPCode&gt;BIP1A172&lt;/</span><br><span class="line">BIPCode&gt;&lt;ActivityCode&gt;T1000167&lt;/ActivityCode&gt;&lt;ActionCode&gt;0&lt;/ActionCode&gt;&lt;/BIPType&gt;&lt;RoutingInfo&gt;&lt;OrigDomain&gt;UPSS&lt;/OrigDomain&gt;&lt;RouteType&gt;01&lt;/RouteType&gt;&lt;Routing&gt;&lt;HomeDomain&gt;BOSS&lt;/HomeDomain&gt;&lt;RouteValue&gt;13962758433&lt;/RouteValue&gt;&lt;/Routing&gt;&lt;/Rou</span><br><span class="line">tingInfo&gt;&lt;TransInfo&gt;&lt;SessionID&gt;202210191612136769940760414152&lt;/SessionID&gt;&lt;TransIDO&gt;202210191612136769940760414152&lt;/TransIDO&gt;&lt;TransIDOTime&gt;20221019161213&lt;/TransIDOTime&gt;&lt;/TransInfo&gt;&lt;/InterBOSS&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;InterBO</span><br><span class="line">SS&gt;&lt;SvcCont&gt;&lt;![CDATA[&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;PaymentReq&gt;&lt;IDType&gt;01&lt;/IDType&gt;&lt;IDValue&gt;13962758433&lt;/IDValue&gt;&lt;TransactionID&gt;10999202210191612136852629215225&lt;/TransactionID&gt;&lt;BusiTransID&gt;20221019161213645000000957081775&lt;/BusiTra</span><br><span class="line">/Exception</span><br><span class="line">...skipping</span><br><span class="line">22/10/19 16:12:33 WARN TmpAppRecharge$: 批处理提交时间：63</span><br><span class="line">22/10/19 16:12:33 ERROR TmpAppRecharge$: 插入充值数据失败：</span><br><span class="line">java.sql.BatchUpdateException: Table has no partition for value from column_list</span><br><span class="line">        at com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:2056)</span><br><span class="line">        at com.mysql.jdbc.PreparedStatement.executeBatch(PreparedStatement.java:1467)</span><br><span class="line">        at com.cmsz.recharge.TmpAppRecharge$$anonfun$main$1$$anonfun$apply$1.apply(TmpAppRecharge.scala:81)</span><br><span class="line">        at com.cmsz.recharge.TmpAppRecharge$$anonfun$main$1$$anonfun$apply$1.apply(TmpAppRecharge.scala:61)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$28.apply(RDD.scala:935)</span><br><span class="line">        at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$28.apply(RDD.scala:935)</span><br><span class="line">        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)</span><br><span class="line">        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)</span><br><span class="line">        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)</span><br><span class="line">        at org.apache.spark.scheduler.Task.run(Task.scala:121)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)</span><br><span class="line">        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1367)</span><br><span class="line">        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: java.sql.SQLException: Table has no partition for value from column_list</span><br><span class="line">        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1078)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4190)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4122)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2570)</span><br><span class="line">        at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2731)</span><br><span class="line">        at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2818)</span><br><span class="line">        at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2157)</span><br><span class="line">        at com.mysql.jdbc.PreparedStatement.executeUpdate(PreparedStatement.java:2460)</span><br><span class="line">        at com.mysql.jdbc.PreparedStatement.executeBatchSerially(PreparedStatement.java:2008)</span><br><span class="line">        ... 15 more</span><br><span class="line">22/10/19 16:12:33 INFO Executor: Finished task 7.0 in stage 5.0 (TID 83). 752 bytes result sent to driver</span><br><span class="line">22/10/19 16:12:33 INFO CoarseGrainedExecutorBackend: Got assigned task 105</span><br><span class="line">22/10/19 16:12:33 INFO Executor: Running task 29.0 in stage 5.0 (TID 105)</span><br><span class="line">22/10/19 16:12:33 WARN TmpAppRecharge$: 批处理提交时间：95</span><br><span class="line">22/10/19 16:12:33 INFO KafkaRDD: Beginning offset 96020515 is the same as ending offset skipping jyupay_cm_log_2 11</span><br><span class="line">22/10/19 16:12:33 INFO KafkaRDD: Computing topic jyupay_own_log_2, partition 8 offsets 17478084 -&gt; 17478093</span><br><span class="line">22/10/19 16:12:33 INFO CachedKafkaConsumer: Cache miss for CacheKey(spark-executor-recharge_tmp2022082606,jyupay_own_log_2,8)</span><br><span class="line">22/10/19 16:12:33 INFO ConsumerConfig: ConsumerConfig values: </span><br><span class="line">        auto.commit.interval.ms = 5000</span><br><span class="line">        auto.offset.reset = none</span><br><span class="line">        bootstrap.servers = [10.252.217.105:6667, 10.252.217.108:6667, 10.252.217.109:6667, 10.252.217.11:6667, 10.252.217.110:6667, 10.252.217.111:6667, 10.252.217.112:6667, 10.252.217.113:6667, 10.252.217.115:6667, 10.252.217.117:6667,</span><br><span class="line"> 10.252.217.12:6667, 10.252.217.120:6667, 10.252.217.121:6667, 10.252.217.123:6667, 10.252.217.125:6667, 10.252.217.128:6667, 10.252.217.129:6667, 10.252.217.13:6667, 10.252.217.134:6667, 10.252.217.135:6667]</span><br><span class="line">        check.crcs = true</span><br><span class="line">        client.id = </span><br><span class="line">        connections.max.idle.ms = 540000</span><br><span class="line">        default.api.timeout.ms = 60000</span><br><span class="line">        enable.auto.commit = false</span><br><span class="line">        exclude.internal.topics = true</span><br><span class="line">        fetch.max.bytes = 52428800</span><br><span class="line">        fetch.max.wait.ms = 500</span><br><span class="line">        fetch.min.bytes = 1</span><br><span class="line">        group.id = spark-executor-recharge_tmp2022082606</span><br><span class="line">        heartbeat.interval.ms = 3000</span><br><span class="line">        interceptor.classes = []</span><br><span class="line">        internal.leave.group.on.close = true</span><br><span class="line">        isolation.level = read_uncommitted</span><br><span class="line">        key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line">        max.partition.fetch.bytes = 1048576</span><br><span class="line">        max.poll.interval.ms = 300000</span><br><span class="line">        max.poll.records = 500</span><br><span class="line">        metadata.max.age.ms = 300000</span><br><span class="line">        metric.reporters = []</span><br><span class="line">        metrics.num.samples = 2</span><br><span class="line">        metrics.recording.level = INFO</span><br><span class="line">        metrics.sample.window.ms = 30000</span><br><span class="line">        partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]</span><br><span class="line">        receive.buffer.bytes = 65536</span><br><span class="line">        reconnect.backoff.max.ms = 1000</span><br><span class="line">        reconnect.backoff.ms = 50</span><br><span class="line">        request.timeout.ms = 100000</span><br><span class="line">        retry.backoff.ms = 100</span><br><span class="line">        sasl.client.callback.handler.class = null</span><br><span class="line">        sasl.jaas.config = null</span><br><span class="line">        sasl.kerberos.kinit.cmd = /usr/bin/kinit</span><br><span class="line">        sasl.kerberos.min.time.before.relogin = 60000</span><br><span class="line">        sasl.kerberos.service.name = null</span><br><span class="line">        sasl.kerberos.ticket.renew.jitter = 0.05</span><br><span class="line">        sasl.kerberos.ticket.renew.window.factor = 0.8</span><br><span class="line">        sasl.login.callback.handler.class = null</span><br><span class="line">        sasl.login.class = null</span><br><span class="line">        sasl.login.refresh.buffer.seconds = 300</span><br><span class="line">        sasl.login.refresh.min.period.seconds = 60</span><br><span class="line">        sasl.login.refresh.window.factor = 0.8</span><br><span class="line">        sasl.login.refresh.window.jitter = 0.05</span><br><span class="line">        sasl.mechanism = GSSAPI</span><br><span class="line">        security.protocol = SASL_PLAINTEXT</span><br><span class="line">        send.buffer.bytes = 131072</span><br><span class="line">        session.timeout.ms = 70000</span><br><span class="line">        ssl.cipher.suites = null</span><br><span class="line">        ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</span><br><span class="line">        ssl.endpoint.identification.algorithm = https</span><br><span class="line">        ssl.key.password = null</span><br><span class="line">        ssl.keymanager.algorithm = SunX509</span><br><span class="line">        ssl.keystore.location = null</span><br><span class="line">        ssl.keystore.password = null</span><br><span class="line">        ssl.keystore.type = JKS</span><br><span class="line">        ssl.protocol = TLS</span><br><span class="line">        ssl.provider = null</span><br><span class="line">        ssl.secure.random.implementation = null</span><br><span class="line">        ssl.trustmanager.algorithm = PKIX</span><br><span class="line">        ssl.truststore.location = null</span><br><span class="line">        ssl.truststore.password = null</span><br><span class="line">        ssl.truststore.type = JKS</span><br><span class="line">        value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</span><br><span class="line"></span><br><span class="line">22/10/19 16:12:33 INFO AppInfoParser: Kafka version : 2.0.0</span><br><span class="line">22/10/19 16:12:33 INFO AppInfoParser: Kafka commitId : 3402a8361b734732</span><br><span class="line">22/10/19 16:12:33 INFO CachedKafkaConsumer: Initial fetch for spark-executor-recharge_tmp2022082606 jyupay_own_log_2 8 17478084</span><br><span class="line">22/10/19 16:12:33 INFO Metadata: Cluster ID: o-pvNtyoQ-eqxIKUVdjRRA</span><br></pre></td></tr></table></figure></code></pre>
]]></content>
      <tags>
        <tag>spark</tag>
        <tag>mysql</tag>
        <tag>try catch</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell脚本提示too many arguments错误</title>
    <url>/Shell%E8%84%9A%E6%9C%AC%E6%8F%90%E7%A4%BAtoo-many-arguments%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="shell脚本执行提示too-many-arguments-错误"><a class="anchor" href="#shell脚本执行提示too-many-arguments-错误">#</a> Shell 脚本执行提示 too many arguments 错误</h1>
<p>程序执行，报错 [: too many , 原因是变量或返回结果中存在空格，系统认为是多个参数，解决方法是将两个判断语句加两个中括号 if [ -n $str];then 更改为 if [[ -n $str ]];then</p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark任务提交失败报错记录</title>
    <url>/Spark%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%A4%B1%E8%B4%A5%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="spark任务提交失败报错记录"><a class="anchor" href="#spark任务提交失败报错记录">#</a> Spark 任务提交失败报错记录</h1>
<h2 id="配置文件定义错误"><a class="anchor" href="#配置文件定义错误">#</a> 配置文件定义错误</h2>
<ol>
<li>Spark 配置文件中，连接 Es 用户的加密密码错误，导致 spark 任务提交失败<br />
 exceptions.EncryptionOperationNotPossibleException</li>
</ol>
<p>错误日志如下：<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/10/28 16:41:53 INFO ApplicationMaster: Waiting for spark context initialization...</span><br><span class="line">22/10/28 16:41:53 ERROR ApplicationMaster: User class threw exception: java.lang.ExceptionInInitializerError</span><br><span class="line">java.lang.ExceptionInInitializerError</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler.main(ChargeFenDuanHandler.scala)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:684)</span><br><span class="line">Caused by: org.jasypt.exceptions.EncryptionOperationNotPossibleException</span><br><span class="line">        at org.jasypt.encryption.pbe.StandardPBEByteEncryptor.decrypt(StandardPBEByteEncryptor.java:1055)</span><br><span class="line">        at org.jasypt.encryption.pbe.StandardPBEStringEncryptor.decrypt(StandardPBEStringEncryptor.java:725)</span><br><span class="line">        at org.jasypt.properties.PropertyValueEncryptionUtils.decrypt(PropertyValueEncryptionUtils.java:72)</span><br><span class="line">        at util.EsUtil.getClinet(EsUtil.java:90)</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler$.&lt;init&gt;(ChargeFenDuanHandler.scala:25)</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler$.&lt;clinit&gt;(ChargeFenDuanHandler.scala)</span><br><span class="line">        ... 6 more</span><br><span class="line">22/10/28 16:41:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 13, (reason: User class threw exception: java.lang.ExceptionInInitializerError</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler.main(ChargeFenDuanHandler.scala)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:684)</span><br><span class="line">Caused by: org.jasypt.exceptions.EncryptionOperationNotPossibleException</span><br><span class="line">        at org.jasypt.encryption.pbe.StandardPBEByteEncryptor.decrypt(StandardPBEByteEncryptor.java:1055)</span><br><span class="line">        at org.jasypt.encryption.pbe.StandardPBEStringEncryptor.decrypt(StandardPBEStringEncryptor.java:725)</span><br><span class="line">        at org.jasypt.properties.PropertyValueEncryptionUtils.decrypt(PropertyValueEncryptionUtils.java:72)</span><br><span class="line">        at util.EsUtil.getClinet(EsUtil.java:90)</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler$.&lt;init&gt;(ChargeFenDuanHandler.scala:25)</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler$.&lt;clinit&gt;(ChargeFenDuanHandler.scala)</span><br><span class="line">        ... 6 more</span><br><span class="line">)</span><br><span class="line">22/10/28 16:41:53 ERROR ApplicationMaster: Uncaught exception: </span><br><span class="line">org.apache.spark.SparkException: Exception thrown in awaitResult: </span><br><span class="line">        at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:468)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster.org$apache$spark$deploy$yarn$ApplicationMaster$$runImpl(ApplicationMaster.scala:305)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$run$1.apply$mcV$sp(ApplicationMaster.scala:245)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$run$1.apply(ApplicationMaster.scala:245)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$run$1.apply(ApplicationMaster.scala:245)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:779)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1685)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster.doAsUser(ApplicationMaster.scala:778)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:244)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:803)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: Boxed Error</span><br><span class="line">        at scala.concurrent.impl.Promise$.resolver(Promise.scala:59)</span><br><span class="line">        at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:51)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)</span><br><span class="line">        at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)</span><br><span class="line">        at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:157)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:703)</span><br><span class="line">Caused by: java.lang.ExceptionInInitializerError</span><br><span class="line">        at com.cmsz.vis.ChargeFenDuanHandler.main(ChargeFenDuanHandler.scala)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:684)</span><br></pre></td></tr></table></figure></p>
<h2 id="group-id问题导致报错"><a class="anchor" href="#group-id问题导致报错">#</a> Group ID 问题导致报错</h2>
<ol start="2">
<li>Spark streaming 消费 kafka 数据时，有多个任务使用相同的 kafka group id 并行消费同一个 topic 导致。排查发现，同一个 spark 任务，启了两个进程。<br />
java.lang.IllegalStateException: No current assignment for partition</li>
</ol>
<p>错误日志如下：<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">22/10/31 16:23:53 ERROR StreamingContext: Error starting the context, marking it as stopped</span><br><span class="line">java.lang.IllegalStateException: No current assignment for partition jyupay_hb_log-8</span><br><span class="line">        at org.apache.kafka.clients.consumer.internals.SubscriptionState.assignedState(SubscriptionState.java:259)</span><br><span class="line">        at org.apache.kafka.clients.consumer.internals.SubscriptionState.seek(SubscriptionState.java:264)</span><br><span class="line">        at org.apache.kafka.clients.consumer.KafkaConsumer.seek(KafkaConsumer.java:1508)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.Subscribe$$anonfun$onStart$2.apply(ConsumerStrategy.scala:107)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.Subscribe$$anonfun$onStart$2.apply(ConsumerStrategy.scala:106)</span><br><span class="line">        at scala.collection.Iterator$class.foreach(Iterator.scala:891)</span><br><span class="line">        at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)</span><br><span class="line">        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)</span><br><span class="line">        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.Subscribe.onStart(ConsumerStrategy.scala:106)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.DirectKafkaInputDStream.consumer(DirectKafkaInputDStream.scala:70)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.DirectKafkaInputDStream.latestOffsets(DirectKafkaInputDStream.scala:181)</span><br><span class="line">        at org.apache.spark.streaming.kafka010.DirectKafkaInputDStream.compute(DirectKafkaInputDStream.scala:209)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)</span><br><span class="line">        at scala.Option.orElse(Option.scala:289)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)</span><br><span class="line">        at org.apache.spark.streaming.dstream.MappedDStream.compute(MappedDStream.scala:36)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)</span><br><span class="line">        at scala.Option.orElse(Option.scala:289)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)</span><br><span class="line">        at org.apache.spark.streaming.dstream.ShuffledDStream.compute(ShuffledDStream.scala:41)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)</span><br><span class="line">        at scala.Option.orElse(Option.scala:289)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$2$$anonfun$apply$29.apply(DStream.scala:901)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$2$$anonfun$apply$29.apply(DStream.scala:900)</span><br><span class="line">        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)</span><br><span class="line">        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)</span><br><span class="line">        at scala.collection.Iterator$class.foreach(Iterator.scala:891)</span><br><span class="line">        at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)</span><br><span class="line">        at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)</span><br><span class="line">        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)</span><br><span class="line">        at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)</span><br><span class="line">        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$2.apply(DStream.scala:900)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$2.apply(DStream.scala:878)</span><br><span class="line">        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)</span><br><span class="line">        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)</span><br><span class="line">        at org.apache.spark.SparkContext.withScope(SparkContext.scala:699)</span><br><span class="line">        at org.apache.spark.streaming.StreamingContext.withScope(StreamingContext.scala:265)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.slice(DStream.scala:878)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$1.apply(DStream.scala:872)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$slice$1.apply(DStream.scala:872)</span><br><span class="line">        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)</span><br><span class="line">        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)</span><br><span class="line">        at org.apache.spark.SparkContext.withScope(SparkContext.scala:699)</span><br><span class="line">        at org.apache.spark.streaming.StreamingContext.withScope(StreamingContext.scala:265)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.slice(DStream.scala:871)</span><br><span class="line">        at org.apache.spark.streaming.dstream.WindowedDStream.compute(WindowedDStream.scala:65)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)</span><br><span class="line">        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)</span><br><span class="line">        at scala.Option.orElse(Option.scala:289)</span><br><span class="line">        at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>kubelet启动报错</title>
    <url>/kubelet%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="kubelet时启动报错"><a class="anchor" href="#kubelet时启动报错">#</a> kubelet 时启动报错</h1>
<pre><code>检查kubelet配置文件kubelet-config.yml，发现某行少一个空格，导致服务启动异常
</code></pre>
<h1 id="错误日志如下"><a class="anchor" href="#错误日志如下">#</a> 错误日志如下：</h1>
<pre><code>journalctl -u kubelet --no-pager
journalctl 的 -u 参数可以指定服务进行过滤，这样可以屏蔽掉其他无关日志。--no-pager 参数可以一次性输出日志，当然如果你只是在线查看，则可以不用这个参数，只是输出日志受到屏幕宽度限制，需要通过方向键滚动
</code></pre>
<pre><code>Oct 21 15:02:01 k8s-master1 systemd[1]: kubelet.service: main process exited, code=exited, status=255/n/a
Oct 21 15:02:01 k8s-master1 systemd[1]: Unit kubelet.service entered failed state.
Oct 21 15:02:01 k8s-master1 systemd[1]: kubelet.service failed.
Oct 21 15:02:01 k8s-master1 systemd[1]: kubelet.service holdoff time over, scheduling restart.
Oct 21 15:02:01 k8s-master1 systemd[1]: Stopped Kubernetes Kubelet.
Oct 21 15:02:01 k8s-master1 systemd[1]: start request repeated too quickly for kubelet.service
Oct 21 15:02:01 k8s-master1 systemd[1]: Failed to start Kubernetes Kubelet.
Oct 21 15:02:01 k8s-master1 systemd[1]: Unit kubelet.service entered failed state.
Oct 21 15:02:01 k8s-master1 systemd[1]: kubelet.service failed.
Oct 21 15:22:04 k8s-master1 systemd[1]: Started Kubernetes Kubelet.
Oct 21 15:22:04 k8s-master1 kubelet[60434]: F1021 15:22:04.573490   60434 server.go:198] failed to load Kubelet config file /opt/kubernetes/cfg/kubelet-config.yml, error failed to decode: yaml: line 14: mapping values are not allowed in this context
Oct 21 15:22:04 k8s-master1 kubelet[60434]: goroutine 1 [running]:
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/k8s.io/klog/v2.stacks(0xc000837901, 0xc0007ce5a0, 0xce, 0x1dc)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/v2/klog.go:996 +0xb9
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/k8s.io/klog/v2.(*loggingT).output(0x6d03160, 0xc000000003, 0x0, 0x0, 0xc00085e460, 0x6b52688, 0x9, 0xc6, 0xc00087cf00)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/v2/klog.go:945 +0x191
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/k8s.io/klog/v2.(*loggingT).printDepth(0x6d03160, 0x3, 0x0, 0x0, 0x1, 0xc000a3fd00, 0x1, 0x1)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/v2/klog.go:718 +0x165
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/k8s.io/klog/v2.(*loggingT).print(...)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/v2/klog.go:703
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/k8s.io/klog/v2.Fatal(...)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/k8s.io/klog/v2/klog.go:1436
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/cmd/kubelet/app.NewKubeletCommand.func1(0xc00045d340, 0xc000128010, 0xa, 0xa)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/cmd/kubelet/app/server.go:198 +0xb25
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).execute(0xc00045d340, 0xc000128010, 0xa, 0xa, 0xc00045d340, 0xc000128010)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:846 +0x2c2
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc00045d340, 0x1720049ab1113e8c, 0x6d02c80, 0x409b05)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:950 +0x375
Oct 21 15:22:04 k8s-master1 kubelet[60434]: k8s.io/kubernetes/vendor/github.com/spf13/cobra.(*Command).Execute(...)
Oct 21 15:22:04 k8s-master1 kubelet[60434]: /workspace/anago-v1.20.0-alpha.0.1624+51ffb495f752fa/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/vendor/github.com/spf13/cobra/command.go:887</code></pre>
]]></content>
      <tags>
        <tag>kubelet</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes二进制包部署时常见错误</title>
    <url>/kubernetes%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85%E9%83%A8%E7%BD%B2%E6%97%B6%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="kubernetes二进制包部署时常见错误"><a class="anchor" href="#kubernetes二进制包部署时常见错误">#</a> kubernetes 二进制包部署时常见错误</h1>
<h2 id="unexpected-end-of-json-input"><a class="anchor" href="#unexpected-end-of-json-input">#</a> unexpected end of JSON input</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@e.160-k8s-node1 k8s] # cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line">Failed to load config file: &#123;&quot;code&quot;:5200,&quot;message&quot;:&quot;could not read configuration file&quot;&#125;Failed to parse input: unexpected end of JSON input</span><br></pre></td></tr></table></figure><br />
 可能是执行命令时 ca、ca-key、config，指定的路径不对</p>
<h2 id="the-connection-to-the-server-localhost8080"><a class="anchor" href="#the-connection-to-the-server-localhost8080">#</a> The connection to the server localhost:8080</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@e.160-k8s-node1 k8s] # kubectl apply -f calico.yaml | kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml</span><br><span class="line">The connection to the server localhost:8080 was refused - did you specify the right host or port?</span><br><span class="line">The connection to the server localhost:8080 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure><br />
 有以下两种解决方式：<br />
1. kubernetes master 没有与本机绑定，集群初始化的时候没有绑定，此时设置在本机的环境变量即可解决问题<br />
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">具体根据情况，此处记录linux设置该环境变量</span><br><span class="line">vim /etc/profile</span><br><span class="line">在底部增加新的环境变量 export KUBECONFIG=/etc/kubernetes/admin.conf，或直接追加文件内容</span><br><span class="line">echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; /etc/profile</span><br></pre></td></tr></table></figure></p>
<pre><code>2. 生成kubectl连接集群的证书
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">	&quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">	&quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">	&#123;</span><br><span class="line">	  &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">	  &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">	  &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">	  &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">	  &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">	&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br><span class="line"></span><br><span class="line">#生成kubeconfig文件</span><br><span class="line">	mkdir /root/.kube</span><br><span class="line">	KUBE_CONFIG=&quot;/root/.kube/config&quot;</span><br><span class="line">	KUBE_APISERVER=&quot;https://192.168.6.81:6443&quot;</span><br><span class="line"></span><br><span class="line">	kubectl config set-cluster kubernetes \</span><br><span class="line">	  --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">	  --embed-certs=true \</span><br><span class="line">	  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">	  --kubeconfig=$&#123;KUBE_CONFIG&#125;</span><br><span class="line">	kubectl config set-credentials cluster-admin \</span><br><span class="line">	  --client-certificate=./admin.pem \</span><br><span class="line">	  --client-key=./admin-key.pem \</span><br><span class="line">	  --embed-certs=true \</span><br><span class="line">	  --kubeconfig=$&#123;KUBE_CONFIG&#125;</span><br><span class="line">	kubectl config set-context default \</span><br><span class="line">	  --cluster=kubernetes \</span><br><span class="line">	  --user=cluster-admin \</span><br><span class="line">	  --kubeconfig=$&#123;KUBE_CONFIG&#125;</span><br><span class="line">	kubectl config use-context default --kubeconfig=$&#123;KUBE_CONFIG&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
]]></content>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>部署Etcd集群启动报错request timed out</title>
    <url>/%E9%83%A8%E7%BD%B2Etcd%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99request-timed-out/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="部署etcd集群启动时报错publish-timeout7serroretcdserver-request-timed-out"><a class="anchor" href="#部署etcd集群启动时报错publish-timeout7serroretcdserver-request-timed-out">#</a> 部署 etcd 集群，启动时报错 &quot;publish-timeout&quot;:&quot;7s&quot;,&quot;error&quot;:&quot;etcdserver: request timed out</h1>
<pre><code>部署好etcd集群，我是先启动一个节点测试，结果启动失败报错。原因是etcd.service中指定了其它主机节点IP，单独启动一个节点，etcd会启动失败，把其它节点etcd.service都restart下即可。
</code></pre>
<h2 id="错误日志如下"><a class="anchor" href="#错误日志如下">#</a> 错误日志如下：</h2>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@e.160-k8s-master1 k8s] less /var/log/messages</span><br><span class="line">Oct 20 15:59:40 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:40.055+0800&quot;,&quot;caller&quot;:&quot;embed/etcd.go:576&quot;,&quot;msg&quot;:&quot;serving peer traffic&quot;,&quot;address&quot;:&quot;192.168.6.81:2380&quot;&#125;</span><br><span class="line">Oct 20 15:59:41 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:41.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 1&quot;&#125;</span><br><span class="line">Oct 20 15:59:41 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:41.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 2&quot;&#125;</span><br><span class="line">Oct 20 15:59:41 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:41.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 2&quot;&#125;</span><br><span class="line">Oct 20 15:59:41 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:41.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 2&quot;&#125;</span><br><span class="line">Oct 20 15:59:41 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:41.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 2&quot;&#125;</span><br><span class="line">Oct 20 15:59:42 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:42.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 2&quot;&#125;</span><br><span class="line">Oct 20 15:59:42 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:42.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 3&quot;&#125;</span><br><span class="line">...skipping...</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.055+0800&quot;,&quot;caller&quot;:&quot;etcdserver/server.go:2065&quot;,&quot;msg&quot;:&quot;failed to publish local member to cluster through raft&quot;,&quot;local-member-id&quot;:&quot;8bf6d3267e7558b2&quot;,&quot;local-member-attributes&quot;:&quot;&#123;Name:etcd-1 ClientURLs:[https://192.168.6.81:2379]&#125;&quot;,&quot;request-path&quot;:&quot;/0/members/8bf6d3267e7558b2/attributes&quot;,&quot;publish-timeout&quot;:&quot;7s&quot;,&quot;error&quot;:&quot;etcdserver: request timed out&quot;&#125;</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.688+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 5&quot;&#125;</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.688+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 6&quot;&#125;</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.688+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 6&quot;&#125;</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.688+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 6&quot;&#125;</span><br><span class="line">Oct 20 15:59:47 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:47.688+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 6&quot;&#125;</span><br><span class="line">Oct 20 15:59:49 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:49.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 6&quot;&#125;</span><br><span class="line">Oct 20 15:59:49 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:49.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 7&quot;&#125;</span><br><span class="line">Oct 20 15:59:49 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:49.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 7&quot;&#125;</span><br><span class="line">Oct 20 15:59:49 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:49.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 7&quot;&#125;</span><br><span class="line">Oct 20 15:59:49 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:49.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 7&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.000+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_SNAPSHOT&quot;,&quot;remote-peer-id&quot;:&quot;15c3e8fb3ea1f770&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.83:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.001+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_RAFT_MESSAGE&quot;,&quot;remote-peer-id&quot;:&quot;15c3e8fb3ea1f770&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.83:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.055+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_RAFT_MESSAGE&quot;,&quot;remote-peer-id&quot;:&quot;69de3e35628a34d1&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.82:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.055+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_SNAPSHOT&quot;,&quot;remote-peer-id&quot;:&quot;69de3e35628a34d1&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.82:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 7&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 8&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 8&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 8&quot;&#125;</span><br><span class="line">Oct 20 15:59:50 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:50.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 8&quot;&#125;</span><br><span class="line">Oct 20 15:59:52 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:52.287+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 8&quot;&#125;</span><br><span class="line">Oct 20 15:59:52 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:52.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 9&quot;&#125;</span><br><span class="line">Oct 20 15:59:52 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:52.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 9&quot;&#125;</span><br><span class="line">Oct 20 15:59:52 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:52.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 9&quot;&#125;</span><br><span class="line">Oct 20 15:59:52 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:52.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 9&quot;&#125;</span><br><span class="line">Oct 20 15:59:53 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:53.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 9&quot;&#125;</span><br><span class="line">Oct 20 15:59:53 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:53.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 10&quot;&#125;</span><br><span class="line">Oct 20 15:59:53 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:53.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 10&quot;&#125;</span><br><span class="line">Oct 20 15:59:53 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:53.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 10&quot;&#125;</span><br><span class="line">Oct 20 15:59:53 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:53.388+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 10&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.056+0800&quot;,&quot;caller&quot;:&quot;etcdserver/server.go:2065&quot;,&quot;msg&quot;:&quot;failed to publish local member to cluster through raft&quot;,&quot;local-member-id&quot;:&quot;8bf6d3267e7558b2&quot;,&quot;local-member-attributes&quot;:&quot;&#123;Name:etcd-1 ClientURLs:[https://192.168.6.81:2379]&#125;&quot;,&quot;request-path&quot;:&quot;/0/members/8bf6d3267e7558b2/attributes&quot;,&quot;publish-timeout&quot;:&quot;7s&quot;,&quot;error&quot;:&quot;etcdserver: request timed out&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.888+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 10&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.888+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 11&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.888+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 11&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.888+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 11&quot;&#125;</span><br><span class="line">Oct 20 15:59:54 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:54.888+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 11&quot;&#125;</span><br><span class="line">Oct 20 15:59:55 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:55.001+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_RAFT_MESSAGE&quot;,&quot;remote-peer-id&quot;:&quot;15c3e8fb3ea1f770&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.83:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:55 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:55.001+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_SNAPSHOT&quot;,&quot;remote-peer-id&quot;:&quot;15c3e8fb3ea1f770&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.83:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:55 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:55.055+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_SNAPSHOT&quot;,&quot;remote-peer-id&quot;:&quot;69de3e35628a34d1&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.82:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:55 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:55.055+0800&quot;,&quot;caller&quot;:&quot;rafthttp/probing_status.go:70&quot;,&quot;msg&quot;:&quot;prober detected unhealthy status&quot;,&quot;round-tripper-name&quot;:&quot;ROUND_TRIPPER_RAFT_MESSAGE&quot;,&quot;remote-peer-id&quot;:&quot;69de3e35628a34d1&quot;,&quot;rtt&quot;:&quot;0s&quot;,&quot;error&quot;:&quot;dial tcp 192.168.6.82:2380: connect: connection refused&quot;&#125;</span><br><span class="line">Oct 20 15:59:56 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:56.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 11&quot;&#125;</span><br><span class="line">Oct 20 15:59:56 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:56.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 12&quot;&#125;</span><br><span class="line">Oct 20 15:59:56 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:56.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 12&quot;&#125;</span><br><span class="line">Oct 20 15:59:56 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:56.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 12&quot;&#125;</span><br><span class="line">Oct 20 15:59:56 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:56.588+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 12&quot;&#125;</span><br><span class="line">Oct 20 15:59:58 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:58.088+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 12&quot;&#125;</span><br><span class="line">Oct 20 15:59:58 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:58.088+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 13&quot;&#125;</span><br><span class="line">Oct 20 15:59:58 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:58.088+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 13&quot;&#125;</span><br><span class="line">Oct 20 15:59:58 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:58.088+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 13&quot;&#125;</span><br><span class="line">Oct 20 15:59:58 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:58.088+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 69de3e35628a34d1 at term 13&quot;&#125;</span><br><span class="line">Oct 20 15:59:59 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:59.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:923&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 is starting a new election at term 13&quot;&#125;</span><br><span class="line">Oct 20 15:59:59 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:59.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:713&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 became candidate at term 14&quot;&#125;</span><br><span class="line">Oct 20 15:59:59 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:59.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:824&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 received MsgVoteResp from 8bf6d3267e7558b2 at term 14&quot;&#125;</span><br><span class="line">Oct 20 15:59:59 k8s-master1 etcd: &#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2022-10-20T15:59:59.288+0800&quot;,&quot;caller&quot;:&quot;raft/raft.go:811&quot;,&quot;msg&quot;:&quot;8bf6d3267e7558b2 [logterm: 1, index: 3] sent MsgVote request to 15c3e8fb3ea1f770 at term 14&quot;&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>CPU负载过高问题排查记录</title>
    <url>/CPU%E8%B4%9F%E8%BD%BD%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="cpu负载过高问题排查记录"><a class="anchor" href="#cpu负载过高问题排查记录">#</a> CPU 负载过高问题排查记录</h1>
<pre><code>top命令查看，cpu占用率已经达到1029.1%，查看pid是flume中心应用占用资源。导出分析jvm日志并无异常，cpu负载过高问题自已恢复。排查发现负载过高时间窗口期间，flume日志有大量新创建的I/O连接，flume节点有连接flume中心失败报错。推测cpu负载过高原因是，网络异常波动，网络恢复后瞬间有大量的数据导致。
</code></pre>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">top - 10:54:14 up 1742 days, 28 min, 7 users, load average: 47. 89, 40. 51, 35. 70 </span><br><span class="line">Tasks: 807 total, 3 running, 803 sleeping, 1 stopped, 0 zombie</span><br><span class="line">Cpu(s) : 17. 2%us, 37. 3%sy, 0. 0%ni, 44. 7%id, 0. 0%wa, 0. 0%hi,  0. 9%si, 0. 0%st</span><br><span class="line">Mem: 529242548k total, 457490336k used, 71752212k free, 1130836k buffers </span><br><span class="line">Swap: 33554424k total, 491472k used, 33062952k free, 266408968k cached</span><br><span class="line">  PID USER PR NI VIRT RES SHR S %CPU %MEM                   TIME+ COMMAND</span><br><span class="line">56290 upays     20   0 77.5g 6.8g 12m S 1029.1 i.3 189636:56 /home/upays/jdkl. 8. 0_60/bin/java -XmslOOm -Xmx64000m -Dcom. sun. management, jmzremote -Djava. security. krb5. conf=/opt/mcb/upays/krb5/krb5. conf -Djava. security, auth. login. config=/o</span><br></pre></td></tr></table></figure></p>
<p>[upays@upayscc ~]$ pwdx 56290<br />
56290: /opt/mcb/upays/flume-center/apache-flume-1.9.0-bin_upay_pay/bin</p>
<p>导出 jvmw 信息<br />
 jstack 56290 &gt; pid_56290.log</p>
<p>根据 PID 查看进程内部线程占用情况<br />
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[upays@upayscc ~]$ top -Hp 56290</span><br><span class="line">  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                                                                         </span><br><span class="line">36817 upays     20   0 77.5g 9.9g  12m S  0.7  2.0 656:53.23 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36703 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 419:30.39 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36707 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 421:35.05 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36718 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 420:00.49 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36720 upays     20   0 77.5g 9.9g  12m S  0.3  2.0  54:17.71 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36721 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 421:17.71 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36727 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 422:43.14 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36735 upays     20   0 77.5g 9.9g  12m S  0.3  2.0 423:37.40 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br><span class="line">36797 upays     20   0 77.5g 9.9g  12m S  0.3  2.0  52:58.32 /home/upays/jdk1.8.0_60/bin/java -Xms100m -Xmx64000m -Dcom.sun.management.jmxremote -Djava.security.krb5.conf=/opt/mcb/upays/krb5/krb5.conf -Djava.security.auth.login.config=/o</span><br></pre></td></tr></table></figure></p>
<p>把进程线程 PID 转换成 16 进制<br />
 [upays@upayscc ~]$ printf &quot;% x\n&quot; 36817<br />
[upays@upayscc ~]$ printf &quot;%x\n&quot; 36817<br />
8fd1</p>
<pre><code>在jvm日志中，根据线程pid十六进制数&quot;8fd1&quot;，查找相关线程信息
pid_56290.log
</code></pre>
<p>查看 flume 中心日志，发现有大量新建立 I/O 连接，日志如下:<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">05 Dec 2022 11:01:15,551 INFO  [New I/O server boss #63] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0xdc8f96af, /172.16.59.164:47956 =&gt; /172.16.59.245:4545] OPEN</span><br><span class="line">05 Dec 2022 11:01:15,552 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-5 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,552 WARN  [kafka-producer-network-thread | producer-311] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-311] Received invalid metadata error in produce request on partition jyupay_py_1-4 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,555 WARN  [kafka-producer-network-thread | producer-311] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-311] Received invalid metadata error in produce request on partition jyupay_py_1-7 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,555 WARN  [kafka-producer-network-thread | producer-311] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-311] Received invalid metadata error in produce request on partition jyupay_py_1-3 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,555 WARN  [kafka-producer-network-thread | producer-311] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-311] Received invalid metadata error in produce request on partition jyupay_py_1-6 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,553 INFO  [New I/O worker #56] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0xdc8f96af, /172.16.59.164:47956 =&gt; /172.16.59.245:4545] BOUND: /172.16.59.245:4545</span><br><span class="line">05 Dec 2022 11:01:15,556 INFO  [New I/O worker #56] (org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream:171)  - [id: 0xdc8f96af, /172.16.59.164:47956 =&gt; /172.16.59.245:4545] CONNECTED: /172.16.59.164:47956</span><br><span class="line">05 Dec 2022 11:01:15,555 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-4 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,558 WARN  [kafka-producer-network-thread | producer-312] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-312] Received invalid metadata error in produce request on partition jyupay_py_1-5 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,554 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-15 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,558 WARN  [kafka-producer-network-thread | producer-312] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-312] Received invalid metadata error in produce request on partition jyupay_py_1-4 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,558 WARN  [kafka-producer-network-thread | producer-317] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-317] Received invalid metadata error in produce request on partition jyupay_py_1-5 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,558 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-7 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,559 WARN  [kafka-producer-network-thread | producer-317] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-317] Received invalid metadata error in produce request on partition jyupay_py_1-4 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,559 WARN  [kafka-producer-network-thread | producer-312] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-312] Received invalid metadata error in produce request on partition jyupay_py_1-7 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,559 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-9 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-14 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-13 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-12 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-1 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-317] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-317] Received invalid metadata error in produce request on partition jyupay_py_1-7 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-3 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-317] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-317] Received invalid metadata error in produce request on partition jyupay_py_1-3 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-18 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,560 WARN  [kafka-producer-network-thread | producer-317] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-317] Received invalid metadata error in produce request on partition jyupay_py_1-2 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,562 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.kafka.KafkaSink.process:255)  - Failed to publish events</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:94)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29)</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:244)</span><br><span class="line">        at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:67)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">05 Dec 2022 11:01:15,562 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-8 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,562 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-3 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,563 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-9 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,563 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.SinkRunner$PollingRunner.run:158)  - Unable to deliver event. Exception follows.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to publish events</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:268)</span><br><span class="line">        at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:67)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:94)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29)</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:244)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">05 Dec 2022 11:01:15,563 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-19 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,563 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.kafka.KafkaSink.process:255)  - Failed to publish events</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:94)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29)</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:244)</span><br><span class="line">        at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:67)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">05 Dec 2022 11:01:15,563 WARN  [kafka-producer-network-thread | producer-297] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-297] Received invalid metadata error in produce request on partition jyupay_py_1-0 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,563 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.SinkRunner$PollingRunner.run:158)  - Unable to deliver event. Exception follows.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to publish events</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:268)</span><br><span class="line">        at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:67)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:94)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29)</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:244)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">05 Dec 2022 11:01:15,563 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-4 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:15,564 WARN  [kafka-producer-network-thread | producer-249] (org.apache.kafka.clients.producer.internals.Sender.completeBatch:568)  - [Producer clientId=producer-249] Received invalid metadata error in produce request on partition jyupay_sc_3-11 due to org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.. Going to request metadata update now</span><br><span class="line">05 Dec 2022 11:01:18,447 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.kafka.KafkaSink.process:255)  - Failed to publish events</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:94)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)</span><br><span class="line">        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29)</span><br><span class="line">        at org.apache.flume.sink.kafka.KafkaSink.process(KafkaSink.java:244)</span><br><span class="line">        at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:67)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.kafka.common.errors.NetworkException: The server disconnected before a response was received.</span><br></pre></td></tr></table></figure></p>
<p>查看 flume 节点日志，发现差不多同一时间，节点主机数据发送到 flume 中心主机失败报错<br />
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[upays@nj-a03-upay-front003 ~]$ tailf -100 /app/upays/flume/apache-flume-1.7.0-bin/bin/logs/flume.log</span><br><span class="line">2022-12-05 10:26:59,782 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.LoadBalancingSinkProcessor.process:160)  - Sink failed to consume event. Attempting next sink if available.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to send events</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:389)</span><br><span class="line">        at org.apache.flume.sink.LoadBalancingSinkProcessor.process(LoadBalancingSinkProcessor.java:156)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: Failed to send batch</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:314)</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:373)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: RPC request timed out</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:399)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:373)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:302)</span><br><span class="line">        ... 4 more</span><br><span class="line">Caused by: java.util.concurrent.TimeoutException</span><br><span class="line">        at org.apache.avro.ipc.CallFuture.get(CallFuture.java:132)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:388)</span><br><span class="line">        ... 6 more</span><br><span class="line">2022-12-05 10:27:05,485 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AbstractRpcSink.createConnection:205)  - Rpc sink k1: Building RpcClient with hostname: 172.16.59.245, port: 4545</span><br><span class="line">2022-12-05 10:27:05,485 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AvroSink.initializeRpcClient:126)  - Attempting to create Avro Rpc client.</span><br><span class="line">2022-12-05 10:27:05,485 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.api.NettyAvroRpcClient.configure:634)  - Using default maxIOWorkers</span><br><span class="line">2022-12-05 10:32:33,129 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.LoadBalancingSinkProcessor.process:160)  - Sink failed to consume event. Attempting next sink if available.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to send events</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:389)</span><br><span class="line">        at org.apache.flume.sink.LoadBalancingSinkProcessor.process(LoadBalancingSinkProcessor.java:156)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: Failed to send batch</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:314)</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:373)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: RPC request timed out</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:399)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:373)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:302)</span><br><span class="line">        ... 4 more</span><br><span class="line">Caused by: java.util.concurrent.TimeoutException</span><br><span class="line">        at org.apache.avro.ipc.CallFuture.get(CallFuture.java:132)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:388)</span><br><span class="line">        ... 6 more</span><br><span class="line">2022-12-05 10:32:43,219 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AbstractRpcSink.createConnection:205)  - Rpc sink k1: Building RpcClient with hostname: 172.16.59.245, port: 4545</span><br><span class="line">2022-12-05 10:32:43,219 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AvroSink.initializeRpcClient:126)  - Attempting to create Avro Rpc client.</span><br><span class="line">2022-12-05 10:32:43,220 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.api.NettyAvroRpcClient.configure:634)  - Using default maxIOWorkers</span><br><span class="line">2022-12-05 10:33:44,938 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.LoadBalancingSinkProcessor.process:160)  - Sink failed to consume event. Attempting next sink if available.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to send events</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:389)</span><br><span class="line">        at org.apache.flume.sink.LoadBalancingSinkProcessor.process(LoadBalancingSinkProcessor.java:156)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: Failed to send batch</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:314)</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:373)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: Handshake timed out after 60000ms</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:358)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:302)</span><br><span class="line">        ... 4 more</span><br><span class="line">Caused by: java.util.concurrent.TimeoutException</span><br><span class="line">        at java.util.concurrent.FutureTask.get(FutureTask.java:205)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:356)</span><br><span class="line">        ... 5 more</span><br><span class="line">2022-12-05 10:33:58,449 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AbstractRpcSink.createConnection:205)  - Rpc sink k1: Building RpcClient with hostname: 172.16.59.245, port: 4545</span><br><span class="line">2022-12-05 10:33:58,449 INFO  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.AvroSink.initializeRpcClient:126)  - Attempting to create Avro Rpc client.</span><br><span class="line">2022-12-05 10:33:58,449 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.api.NettyAvroRpcClient.configure:634)  - Using default maxIOWorkers</span><br><span class="line">2022-12-05 10:36:55,218 WARN  [SinkRunner-PollingRunner-LoadBalancingSinkProcessor] (org.apache.flume.sink.LoadBalancingSinkProcessor.process:160)  - Sink failed to consume event. Attempting next sink if available.</span><br><span class="line">org.apache.flume.EventDeliveryException: Failed to send events</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:389)</span><br><span class="line">        at org.apache.flume.sink.LoadBalancingSinkProcessor.process(LoadBalancingSinkProcessor.java:156)</span><br><span class="line">        at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:145)</span><br><span class="line">        at java.lang.Thread.run(Thread.java:748)</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: Failed to send batch</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:314)</span><br><span class="line">        at org.apache.flume.sink.AbstractRpcSink.process(AbstractRpcSink.java:373)</span><br><span class="line">        ... 3 more</span><br><span class="line">Caused by: org.apache.flume.EventDeliveryException: NettyAvroRpcClient &#123; host: 172.16.59.245, port: 4545 &#125;: RPC request timed out</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:399)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:373)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.appendBatch(NettyAvroRpcClient.java:302)</span><br><span class="line">        ... 4 more</span><br><span class="line">Caused by: java.util.concurrent.TimeoutException</span><br><span class="line">        at org.apache.avro.ipc.CallFuture.get(CallFuture.java:132)</span><br><span class="line">        at org.apache.flume.api.NettyAvroRpcClient.waitForStatusOK(NettyAvroRpcClient.java:388)</span><br><span class="line">        ... 6 more</span><br></pre></td></tr></table></figure></p>
]]></content>
      <tags>
        <tag>cpu</tag>
      </tags>
  </entry>
</search>
